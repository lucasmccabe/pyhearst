import re
import string
import nltk
from nltk.tokenize.treebank import TreebankWordDetokenizer
from typing import List
import inflect

class PyHearst:
    '''PyHearst class.'''

    def __init__(self):
        '''
        Constructor for the PyHearst class.

        self.patterns: list of tuples, which each tuple formatted as:
            (regex for Hearst pattern, hypernym identifier)
            if hypernym identifier == 0, the first NP is the hypernym
            if hypernym identifier == 1, the last NP is the hypernym

        self.tests: list of test phrases, roughly derived from the
            Hearst paper's examples
        '''

        self.patterns = [('(such NP_[\w.]* as NP_[\w.]*(,? (and | or )?NP_[\w.]*)*)', 0),
                           ('(NP_[\w.]*,? such as NP_[\w.]*(,? (and | or )?NP_[\w.]*)*)', 0),
                           ('(NP_[\w.]*(, NP_[\w.]*)*,? (and|or)? other NP_[\w.]*)', 1),
                           ('(NP_[\w.]*,? including NP_[\w.]*(,? (and | or )?NP_[\w.]*)*)', 0),
                           ('(NP_[\w.]*,? especially NP_[\w.]*(,? (and | or )?NP_[\w.]*)*)', 0)
                          ]

        self.tests = ['works by such individuals as Marti A. Hearst, P. J. Proudhon, and Esther Duflo and also foods such as pancakes, waffles, and eggs',
                         'bruises, wounds, bones, or other injuries',
                         'sports such as basketball and baseball',
                         'beans, such as pinto and kidney',
                         'temples, treasuries, and other buildings',
                         'countries, including Canada and England',
                         'countries, especially France, England, and Spain'
                        ]

    def annotate_sentence(self, sent: str) -> str:
        '''
        Tags NPs inline. Leans on merge_consecutive_NPs() at the end to handle
        consecutive NPs (e.g.: J. K. Rowling).

        Args:
            sent: text string to extract hyponym relations from
        Returns:
            annotated_sentence with NPs tagged

        Example Usage:
            >>> text = 'works by such authors as J. K. Rowling, Goldsmith, and Shakespeare.'
            >>> ph = PyHearst()
            >>> print(ph.annotate_sentence(text))
            'NP_works by such NP_authors as NP_J._K._Rowling, NP_Goldsmith, and NP_Shakespeare.'
        '''
        tagged_sent = nltk.pos_tag(nltk.word_tokenize(sent))

        NPs = set([tup[0] for tup in tagged_sent if tup[1].startswith('NN')])
        for NP in NPs:
            sent = sent.replace(NP, 'NP_'+NP) #adds NP tag

        return self.merge_consecutive_NPs(sent)


    def merge_consecutive_NPs(self, annotated_sentence: str) -> str:
        '''
        Merges consecutive tagged NPs in an annotated sentence.

        Args:
            annotated_sentence: NP_-annotated sentence as generated by annotate_sentence()
        Returns:
            annotated_sentence with consecutive NPs merged and initialed NPs handled

        Example Usage:
            >>> annotated_sentence = 'NP_works by such NP_authors as NP_J. NP_K. NP_Rowling, NP_Goldsmith, and NP_Shakespeare.'
            >>> ph = PyHearst()
            >>> print(ph.merge_consecutive_NPs(annotated_sentence))
            'NP_works by such NP_authors as NP_J._K._Rowling, NP_Goldsmith, and NP_Shakespeare.'
        '''

        toks = nltk.word_tokenize(annotated_sentence)

        #merge initialed NPs to handle instances like J. K. Rowling
        for i in range(len(toks)-1, 0, -1):
            if toks[i] == '.' and i!= len(toks)-1:
                toks[i-1:i+1] = [toks[i-1] + toks[i]]

        NP_indices = [i for i in range(len(toks)) if toks[i].startswith('NP_')] #inidices of all NP_-tagged tokens

        #if two consecutive tokens are tagged NP_, then merge them into one token
        for i in range(len(NP_indices)-1, 0, -1):
            if NP_indices[i]-1 == NP_indices[i-1]:
                toks[NP_indices[i-1]:NP_indices[i]+1] = [toks[NP_indices[i-1]] +'_' + toks[NP_indices[i]][3:]]

        #untokenize and return:
        return ''.join([' '+tok if not tok.startswith('\'') and
                        tok not in string.punctuation else
                        tok for tok in toks]).strip()



    def extract_patterns(self, sent: str) -> List:
        '''
        Identifies Hearst patterns and returns a list of hyponym relations.

        Args:
            sent: text string to extract hyponym relations from
        Returns:
            hyponym_relations: list of hyponym relations, formatted as tuples of form (hypernym, hyponym)

        Example Usage:
            >>> hearst_patterns = [('such (NP_\w+) as (NP_\w+.*)(, (and | or )*NP_\w+)*', 0)]
            >>> text = 'works by such individuals as Marti A. Hearst, P. J. Proudhon, and Esther Duflo and also foods such as pancakes, waffles, and eggs'
            >>> for pattern in extract_patterns(hearst_patterns, text): print(pattern)
            ('individual', 'Marti A. Hearst')
            ('individual', 'P. J. Proudhon')
            ('individual', 'Esther Duflo')
            ('food', 'pancakes')
            ('food', 'waffles')
            ('food', 'eggs')
        '''

        in_eng = inflect.engine()
        annotated_sentence = self.annotate_sentence(sent)

        hyponym_relations = [] #format is tuples of form (hypernym, hyponym)
        for pattern in self.patterns:
            matches = re.findall(pattern[0], annotated_sentence) #get each instance of the regex pattern

            for match in matches:
                instance = match[0]

                NPs = [tok.replace('NP_', '').replace('_', ' ')
                       for tok in nltk.word_tokenize(instance)
                       if tok.startswith('NP_')]

                if NPs:
                    if pattern[1] == 0:
                        #the first NP is the hypernym
                        hypernym = NPs[0]
                    if pattern[1] == 1:
                        #the last NP is the hypernym
                        hypernym = NPs[len(NPs)-1]

                    hyponyms = [NP for NP in NPs if NP != hypernym]

                    for hyponym in hyponyms:
                        if in_eng.singular_noun(hyponym)==False:
                            hyponym_relations.append(
                                (in_eng.singular_noun(hypernym), hyponym))
                        else:
                            hyponym_relations.append(
                                (in_eng.singular_noun(hypernym),
                                in_eng.singular_noun(hyponym)))

        return hyponym_relations
